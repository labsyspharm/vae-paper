{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9beac609-5002-4440-9a08-1504d24dd1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import yaml\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import cm\n",
    "\n",
    "import napari\n",
    "\n",
    "from utils.utility_functions import single_channel_pyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "195d4c70-7e0e-47d7-906d-a9c4ec039bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to \"smb://files.med.harvard.edu/ImStor/sorger/data/RareCyte\" to read SARDANA-102 image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de2bb23a-5e41-4d37-b873-b5e44cb3645d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# read unclustered single-cell data or SARDANA-102 image \u001b[39;00m\n\u001b[1;32m     11\u001b[0m sc_data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Volumes/RareCyte/JL503_JERRY/TNP_2020/mcmicro-20200922/WD-76845-102.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 12\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43msc_data_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# import markers.csv\u001b[39;00m\n\u001b[1;32m     15\u001b[0m markers \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput/CRC-097_mcmicro_markers.csv\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/venvs/vae/lib/python3.9/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/vae/lib/python3.9/site-packages/pandas/io/parsers/readers.py:617\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/vae/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1748\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1741\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m     (\n\u001b[1;32m   1745\u001b[0m         index,\n\u001b[1;32m   1746\u001b[0m         columns,\n\u001b[1;32m   1747\u001b[0m         col_dict,\n\u001b[0;32m-> 1748\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1749\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/venvs/vae/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:843\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:904\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:879\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:890\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2058\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "# I/O\n",
    "\n",
    "# read OME-TIFF and segmentation outlines\n",
    "tif_path = '/Volumes/RareCyte/JL503_JERRY/TNP_2020/WD-76845-102.ome.tif'\n",
    "seg_path = (\n",
    "    '/Volumes/RareCyte/JL503_JERRY/TNP_2020/mcmicro-20200922/'\n",
    "    'WD-76845-102/qc/s3seg/unmicst-WD-76845-102/nucleiRingOutlines.tif'\n",
    ")\n",
    "\n",
    "# read unclustered single-cell data or SARDANA-102 image \n",
    "sc_data_path = '/Volumes/RareCyte/JL503_JERRY/TNP_2020/mcmicro-20200922/WD-76845-102.csv'\n",
    "data = pd.read_csv(sc_data_path)\n",
    "\n",
    "# import markers.csv\n",
    "markers = pd.read_csv(os.path.join(os.getcwd(), 'input/CRC-097_mcmicro_markers.csv'))\n",
    "\n",
    "# import image contrast settings\n",
    "with open(os.path.join(os.getcwd(), 'input/CRC-097_cylinter_contrast_limits.yml')) as f:\n",
    "    contrast_limits = yaml.safe_load(f)\n",
    "\n",
    "# The parquet file at the path below is being read because \"main.csv\" \n",
    "# uses trimmed marker channel names as column headers that differ from the raw channel names used \n",
    "# in the markers.csv file used to index channels in the OME-TIFF image.\n",
    "for_channels = pd.read_parquet(\n",
    "    os.path.join(os.getcwd(), 'input/CRC-097_clean_cylinter_clustering_3d_leiden.parquet')\n",
    ")\n",
    "\n",
    "# isolate antibodies of interest\n",
    "abx_channels = [i for i in for_channels.columns if 'nucleiRingMask' in i if 'Hoechst' not in i]\n",
    "\n",
    "# read cluster labels for SARADANA-102 (VAE20 model applied, HDBSCAN clustering)\n",
    "clusters = pd.read_csv(os.path.join(os.getcwd(), 'input/vae102_clustering_solution_MCS150_NN30_RS3_Rand3.csv'))\n",
    "\n",
    "# merge with single-cell dataframe\n",
    "data = data.merge(clusters, how='inner', on='CellID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8a992d-3a60-49da-aabe-2237277b4a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize image viewer\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "# add DNA1 channel to Napari image viewer\n",
    "dna, min, max = single_channel_pyramid(glob.glob(tif_path)[0], channel=0)\n",
    "viewer.add_image(\n",
    "    dna, rgb=False, blending='additive',\n",
    "    colormap='gray', visible=True, opacity=1.0,\n",
    "    name='DNA1', contrast_limits=(min, max)\n",
    ")\n",
    "\n",
    "# add marker channels and apply previously defined contrast limits\n",
    "for ch in abx_channels:\n",
    "    ch = ch.rsplit('_', 1)[0]\n",
    "    channel_number = markers['channel_number'][markers['marker_name'] == ch]\n",
    "    img, min, max = single_channel_pyramid(\n",
    "        glob.glob(tif_path)[0], channel=(channel_number.item() - 1)\n",
    "    )\n",
    "    viewer.add_image(\n",
    "        img, rgb=False, blending='additive', colormap='green', visible=False, name=ch,\n",
    "        contrast_limits=(min, max)\n",
    "    )\n",
    "for ch in abx_channels:\n",
    "    ch = ch.rsplit('_', 1)[0]\n",
    "    viewer.layers[ch].contrast_limits = (\n",
    "        contrast_limits[ch][0], contrast_limits[ch][1])\n",
    "\n",
    "# add centroids of cells for each VAE cluster to image viewer\n",
    "num_colors = len(list(cm.tab20.colors))\n",
    "num_clusters = len(data['vae_cluster'].unique())\n",
    "palette_multiplier = ceil(num_clusters / num_colors)\n",
    "colors = list(cm.tab20.colors) * palette_multiplier\n",
    "colors = colors[0:num_clusters]\n",
    "colors.reverse()\n",
    "\n",
    "for c, cluster in zip(colors, sorted(data['vae_cluster'].unique(), reverse=True)):\n",
    "    centroids = data[['Y_centroid', 'X_centroid']][data['vae_cluster'] == cluster]\n",
    "    viewer.add_points(\n",
    "        centroids, name=f'VAE{cluster}', face_color=np.array(c), edge_color='white',\n",
    "        edge_width=0.0, size=3.0, opacity=1.0, blending='translucent', visible=False\n",
    "    )\n",
    "\n",
    "# read segmentation outlines\n",
    "seg, min, max = single_channel_pyramid(glob.glob(seg_path)[0], channel=0)\n",
    "viewer.add_image(\n",
    "    seg, rgb=False, blending='additive',\n",
    "    colormap='gray', visible=False,\n",
    "    name='segmentation', opacity=0.3, contrast_limits=(min, max)\n",
    ")\n",
    "\n",
    "# run image viewer\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.scale_bar.unit = 'um'\n",
    "\n",
    "napari.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
