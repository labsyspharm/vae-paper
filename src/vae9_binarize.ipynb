{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f2b6ec0-4fa2-4ed0-a48d-d9c56caed630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import shutil\n",
    "import pathlib\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41d54c20-9e6d-417e-bf1d-3a98d2708b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_binary_masks_with_clipped_limits(original_images, contrast_limits_per_channel):\n",
    "    \"\"\"\n",
    "    Create binary masks from original images based on specified contrast limits for each channel.\n",
    "\n",
    "    Parameters:\n",
    "    - original_images (zarr array): The input array of original images with shape (n_channels, height, width).\n",
    "    - contrast_limits_per_channel (dict): A dictionary where keys are channel names and values are the minimum \n",
    "                                          contrast limit values for the corresponding channel.\n",
    "\n",
    "    Returns:\n",
    "    - binary_masks_array (zarr array): An array of binary masks with the same shape as original_images, where each pixel \n",
    "                                       is set to 1 if its value in original_images exceeds the corresponding channel's \n",
    "                                       minimum contrast limit, otherwise set to 0.\n",
    "    \"\"\"\n",
    "    binary_masks_array = zarr.zeros_like(original_images)  \n",
    "    \n",
    "    # Loop over the channels\n",
    "    for i in range(original_images.shape[0]):  \n",
    "        channel_name = list(contrast_limits_per_channel.keys())[i]\n",
    "        min_val = contrast_limits_per_channel[channel_name]\n",
    "\n",
    "        print(min_val)\n",
    "        # Create binary mask using the minimum value as threshold\n",
    "        binary_masks_array[i] = np.where(original_images[i] > min_val, 1, 0).astype(np.uint16)\n",
    "    \n",
    "    return binary_masks_array\n",
    "\n",
    "\n",
    "\n",
    "def remove_sparse_images(binary_patches, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Remove images from the binary_patches array where the percentage of zeros exceeds a given threshold.\n",
    "    \n",
    "    Parameters:\n",
    "    - binary_patches (numpy array): The input array of binary images with shape (n_batches, n_images, height, width).\n",
    "    - threshold (float): The threshold for the percentage of zeros in an image to determine if it should be removed.\n",
    "\n",
    "    Returns:\n",
    "    - binary_patches_subset (numpy array): The subset of binary_patches array after removing images exceeding the threshold.\n",
    "    - indices_to_remove (numpy array): The indices of images removed.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the total number of pixels in each image\n",
    "    total_pixels = binary_patches.shape[2] * binary_patches.shape[3]\n",
    "\n",
    "    # Calculate the number of zeros in each image\n",
    "    num_zeros_per_image = np.sum(binary_patches[0] == 0, axis=(1, 2))\n",
    "\n",
    "    # Calculate the percentage of zeros in each image\n",
    "    percentage_zeros_per_image = num_zeros_per_image / total_pixels\n",
    "\n",
    "    # Create a boolean mask indicating images where the percentage of zeros exceeds the threshold\n",
    "    mask = percentage_zeros_per_image > threshold\n",
    "\n",
    "    # Find the indices of images where the percentage of zeros exceeds the threshold\n",
    "    indices_to_remove = np.where(mask)[0]\n",
    "\n",
    "    # Remove these indices from the array\n",
    "    binary_patches_subset = np.delete(binary_patches, indices_to_remove, axis=1)\n",
    "\n",
    "    return binary_patches_subset, indices_to_remove\n",
    "\n",
    "# Function to drop indices from a Zarr array\n",
    "def drop_indices_from_zarr(zarr_array, indices_to_drop):\n",
    "    remaining_indices = np.setdiff1d(np.arange(zarr_array.shape[1]), indices_to_drop)\n",
    "    return zarr_array[:, remaining_indices, :, :]\n",
    "    \n",
    "def add_cluster_column_for_split(df, main_df, clustering_to_append):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): The split dataframe which will receive the clustering column.\n",
    "    - main_df (DataFrame): The main dataframe containing all the clustering columns.\n",
    "    - clustering_to_append (str): The clustering column to append to the split dataframe.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: The updated split dataframe with the clustering column added.\n",
    "    \"\"\"\n",
    "    # Merge the split dataframe with the main dataframe based on CellID\n",
    "    df = df.merge(main_df[['CellID', clustering_to_append]], on='CellID', how='left')\n",
    "    return df\n",
    "\n",
    "\n",
    "def filter_clusters(df, clustering_column, clusters_to_keep):\n",
    "    \"\"\"\n",
    "    Filter the dataframe to keep only specified clusters and save the dropped indices and CellIDs.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): The dataframe to be filtered.\n",
    "    - clustering_column (str): The clustering column to filter on.\n",
    "    - clusters_to_keep (list): List of clusters to keep.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: The filtered dataframe.\n",
    "    - list: The list of indices that were dropped.\n",
    "    - list: The list of CellIDs of the dropped indices.\n",
    "    \"\"\"\n",
    "    # Identify rows to drop\n",
    "    mask_to_drop = ~df[clustering_column].isin(clusters_to_keep)\n",
    "    indices_dropped = df.index[mask_to_drop].tolist()\n",
    "    cellids_dropped = df.loc[mask_to_drop, 'CellID'].tolist()\n",
    "\n",
    "    # Drop the rows\n",
    "    df_filtered = df[~mask_to_drop].reset_index(drop=True)\n",
    "\n",
    "    return df_filtered, indices_dropped, cellids_dropped\n",
    "\n",
    "def drop_indices_from_zarr(zarr_array, indices_to_drop):\n",
    "    \"\"\"\n",
    "    Drop the specified indices from the Zarr array.\n",
    "\n",
    "    Parameters:\n",
    "    - zarr_array (zarr array): The input Zarr array.\n",
    "    - indices_to_drop (list): List of indices to drop.\n",
    "\n",
    "    Returns:\n",
    "    - zarr array: The updated Zarr array with specified indices dropped.\n",
    "    \"\"\"\n",
    "    remaining_indices = np.setdiff1d(np.arange(zarr_array.shape[1]), indices_to_drop)\n",
    "    return zarr_array[:, remaining_indices, :, :], remaining_indices\n",
    "\n",
    "def zip_zarr_directory(directory_path, zip_file_path):\n",
    "    \"\"\"\n",
    "    Zip the contents of the given Zarr directory into a ZIP file.\n",
    "\n",
    "    Parameters:\n",
    "    - directory_path (str): The path to the Zarr directory.\n",
    "    - zip_file_path (str): The path to the output ZIP file.\n",
    "    \"\"\"\n",
    "    dir_path = pathlib.Path(directory_path)\n",
    "    with zipfile.ZipFile(zip_file_path, \"w\", compression=zipfile.ZIP_STORED) as zf:\n",
    "        for f in dir_path.rglob(\"*\"):\n",
    "            zf.write(f, f.relative_to(dir_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f30a8b5-84ae-4a47-9e48-2dae5d0cce21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify VAE clustering of interest and associated window size and latent dimension\n",
    "vae_output_dir = '/Users/hitsloaner/Downloads/VAE9_VIG7'   #SPECIFY PATH OF YOUR VAE WINDOW\n",
    "clustering = 'VAE9_VIG7'\n",
    "window_size = 14  # in pixels\n",
    "latent_dim = 850\n",
    "\n",
    "# Define the contrast limits for each channel\n",
    "contrast_limits = {\n",
    "    'Keratin_570': 9500,  # Channel 0 in z_subset\n",
    "    'Ecad_488': 5000,  # Channel 1 in z_subset\n",
    "    'PCNA_488': 8000.0  # Channel 2 in z_subset\n",
    "}\n",
    "\n",
    "# load the original zarr patches for that window size\n",
    "directory = f'{vae_output_dir}/2_cellcutter_output_win{window_size}/'\n",
    "\n",
    "main_csv = '/Users/hitsloaner/Downloads/main_all_clustering.csv'  # SPECIFY PATH OF YOUR MAIN CLUSTERING FILE\n",
    "\n",
    "main = pd.read_csv(main_csv)\n",
    "\n",
    "tumor_clusters_for_analysis = [0, 1, 3, 5, 6, 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09785438-a165-4c11-b3dd-bad5c731e540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check passed: Initial indices match between CSV files and Zarr files.\n"
     ]
    }
   ],
   "source": [
    "splits = ['train', 'test', 'validate']\n",
    "\n",
    "# Sanity check: Compare kept indices between the original CSV files and Zarr files\n",
    "for split in splits:\n",
    "    csv_of_split_path = f'{vae_output_dir}/1_cellcutter_input/{split}.csv'\n",
    "    csv_file = pd.read_csv(csv_of_split_path)\n",
    "\n",
    "    # Add the clustering column to the split CSV file\n",
    "    csv_file_with_clustering_column = add_cluster_column_for_split(csv_file, main, clustering)\n",
    "\n",
    "    # Initial indices of the CSV file before any filtering\n",
    "    initial_indices_csv = set(csv_file_with_clustering_column.index)\n",
    "\n",
    "    # Load the regular file\n",
    "    regular_file = f\"{split}_thumbnails_{window_size}.zip\"\n",
    "    regular_path = os.path.join(directory, regular_file)\n",
    "\n",
    "    if os.path.exists(regular_path):\n",
    "        z_store = zarr.ZipStore(regular_path, mode='r')\n",
    "        z = zarr.open(store=z_store)\n",
    "        \n",
    "        initial_indices_zarr = set(np.arange(z.shape[1]))\n",
    "\n",
    "        # Check if the initial indices are the same\n",
    "        assert initial_indices_csv == initial_indices_zarr, f\"Initial indices mismatch in {split} split\"\n",
    "\n",
    "print(\"Sanity check passed: Initial indices match between CSV files and Zarr files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bce9f5e3-9ef2-4972-9f9a-5f7193c8d6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 16267, 14, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d9cfaf6-719b-49d4-9015-a6e197dab9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - Indices dropped after clustering filter: 238718\n",
      "train - CellIDs dropped after clustering filter: 238718\n",
      "9500\n",
      "5000\n",
      "8000.0\n",
      "train - Additional indices dropped after binarization: 14403\n",
      "Checking if segmentation shape is same as image shape: True\n",
      "test - Indices dropped after clustering filter: 29674\n",
      "test - CellIDs dropped after clustering filter: 29674\n",
      "9500\n",
      "5000\n",
      "8000.0\n",
      "test - Additional indices dropped after binarization: 1776\n",
      "Checking if segmentation shape is same as image shape: True\n",
      "validate - Indices dropped after clustering filter: 29769\n",
      "validate - CellIDs dropped after clustering filter: 29769\n",
      "9500\n",
      "5000\n",
      "8000.0\n",
      "validate - Additional indices dropped after binarization: 1874\n",
      "Checking if segmentation shape is same as image shape: True\n",
      "Processing completed. Indices saved.\n"
     ]
    }
   ],
   "source": [
    "# Lists to track all removed indices\n",
    "all_removed_indices_from_csv = []\n",
    "all_removed_indices_from_zarr = []\n",
    "all_kept_indices = []\n",
    "\n",
    "# Loop over each split and process\n",
    "for split in splits:\n",
    "\n",
    "    # Preprocess CSV files\n",
    "    csv_of_split_path = f'{vae_output_dir}/1_cellcutter_input/{split}.csv'\n",
    "    csv_file = pd.read_csv(csv_of_split_path)\n",
    "\n",
    "    # Create a backup of the original CSV file\n",
    "    csv_backup_path = f'{vae_output_dir}/1_cellcutter_input/{split}_backup.csv'\n",
    "    shutil.copy(csv_of_split_path, csv_backup_path)\n",
    "\n",
    "    # Add the clustering column to the split CSV file\n",
    "    csv_file_with_clustering_column = add_cluster_column_for_split(csv_file, main, clustering)\n",
    "    \n",
    "    # Filter the dataframe to keep only specified clusters and save dropped indices and CellIDs\n",
    "    filtered_csv_file, indices_dropped_from_csv, cellids_dropped = filter_clusters(csv_file_with_clustering_column, clustering, tumor_clusters_for_analysis)\n",
    "    \n",
    "    # Print the number of dropped indices and CellIDs\n",
    "    print(f\"{split} - Indices dropped after clustering filter:\", len(indices_dropped_from_csv))\n",
    "    print(f\"{split} - CellIDs dropped after clustering filter:\", len(cellids_dropped))\n",
    "\n",
    "    # Add to the list of all removed indices from the CSV\n",
    "    all_removed_indices_from_csv.extend(indices_dropped_from_csv)\n",
    "\n",
    "    # DO ZARR PROCESSING\n",
    "    regular_file = f\"{split}_thumbnails_{window_size}.zip\"\n",
    "    seg_file = f\"{split}_thumbnails_{window_size}_seg.zip\"\n",
    "    \n",
    "    # Construct the full paths\n",
    "    regular_path = os.path.join(directory, regular_file)\n",
    "    seg_path = os.path.join(directory, seg_file)\n",
    "    \n",
    "    # Load the regular file\n",
    "    if os.path.exists(regular_path):\n",
    "        z_store = zarr.ZipStore(regular_path, mode='r')\n",
    "        z = zarr.open(store=z_store)\n",
    "        \n",
    "        # Drop the identified indices from the Zarr array\n",
    "        z_tumor_only, remaining_indices_after_filter = drop_indices_from_zarr(z, indices_dropped_from_csv)\n",
    "\n",
    "        # Subset channels of interest (i.e. we are interested in tumor relevant markers Keratin, ECAD, and PCNA)\n",
    "        channels = [2, 3, 19]\n",
    "        z_subset = z_tumor_only[channels, :, :, :]\n",
    "\n",
    "        # Binarize and filter the Zarr patches to remove sparse areas\n",
    "        z_binary = create_binary_masks_with_clipped_limits(z_subset, contrast_limits) \n",
    "        z_filtered, indices_to_remove_from_zarr = remove_sparse_images(z_binary, threshold=0.8)\n",
    "\n",
    "        # Add to the list of all removed indices from the Zarr array\n",
    "        all_removed_indices_from_zarr.extend(indices_to_remove_from_zarr)\n",
    "\n",
    "        # Further drop these indices from the filtered CSV file\n",
    "        filtered_csv_file = filtered_csv_file.drop(indices_to_remove_from_zarr).reset_index(drop=True)\n",
    "\n",
    "        # Print the number of additional dropped indices\n",
    "        print(f\"{split} - Additional indices dropped after binarization:\", len(indices_to_remove_from_zarr))\n",
    "\n",
    "        # Save the filtered regular Zarr array\n",
    "        zarr_filtered_path = os.path.join(directory, f'{split}_thumbnails_{window_size}')\n",
    "        zarr_filtered_store = zarr.DirectoryStore(zarr_filtered_path)\n",
    "        zarr_filtered = zarr.open(store=zarr_filtered_store, mode='w', shape=z_filtered.shape, dtype=z_filtered.dtype)\n",
    "        zarr_filtered[:] = z_filtered\n",
    "\n",
    "        # Zip the filtered regular Zarr array\n",
    "        zip_zarr_directory(zarr_filtered_path, f'{directory}/{split}_thumbnails_{window_size}.zip')\n",
    "        shutil.rmtree(zarr_filtered_path)  # Remove the unzipped directory after zipping\n",
    "\n",
    "        # Drop the same indices from the _seg Zarr array\n",
    "        if os.path.exists(seg_path):\n",
    "            seg_store = zarr.ZipStore(seg_path, mode='r')\n",
    "            seg = zarr.open(store=seg_store)\n",
    "            \n",
    "            # Drop indices from seg array based on initial tumor filtering\n",
    "            seg_tumor_only, _ = drop_indices_from_zarr(seg, indices_dropped_from_csv)\n",
    "            \n",
    "            # Drop indices from seg array based on further filtering\n",
    "            seg_filtered, _ = drop_indices_from_zarr(seg_tumor_only, indices_to_remove_from_zarr)\n",
    "\n",
    "            # Save the filtered seg Zarr array\n",
    "            seg_filtered_path = os.path.join(directory, f'{split}_thumbnails_{window_size}_seg')\n",
    "            seg_filtered_store = zarr.DirectoryStore(seg_filtered_path)\n",
    "            zarr_seg_filtered = zarr.open(store=seg_filtered_store, mode='w', shape=seg_filtered.shape, dtype=seg_filtered.dtype)\n",
    "            zarr_seg_filtered[:] = seg_filtered\n",
    "\n",
    "            # Zip the filtered seg Zarr array\n",
    "            zip_zarr_directory(seg_filtered_path, f'{directory}/{split}_thumbnails_{window_size}_seg.zip')\n",
    "            shutil.rmtree(seg_filtered_path)  # Remove the unzipped directory after zipping\n",
    "\n",
    "        # Track the kept indices\n",
    "        final_kept_indices = np.setdiff1d(remaining_indices_after_filter, indices_to_remove_from_zarr)\n",
    "        all_kept_indices.extend(final_kept_indices)\n",
    "\n",
    "    print(\"Checking if segmentation shape is same as image shape:\", seg_filtered.shape[1] == z_filtered.shape[1])\n",
    "\n",
    "    # Save the final filtered CSV file (replacing the original file)\n",
    "    filtered_csv_file.to_csv(csv_of_split_path, index=False)\n",
    "\n",
    "# Convert the lists of all removed and kept indices to numpy arrays and save\n",
    "all_removed_indices_from_csv = np.array(all_removed_indices_from_csv)\n",
    "all_removed_indices_from_zarr = np.array(all_removed_indices_from_zarr)\n",
    "all_kept_indices = np.array(all_kept_indices)\n",
    "\n",
    "np.save(f'{vae_output_dir}/all_removed_indices_from_csv.npy', all_removed_indices_from_csv)\n",
    "np.save(f'{vae_output_dir}/all_removed_indices_from_zarr.npy', all_removed_indices_from_zarr)\n",
    "np.save(f'{vae_output_dir}/all_kept_indices.npy', all_kept_indices)\n",
    "\n",
    "print(\"Processing completed. Indices saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebe2201-4cc5-4553-9c1c-b95a7754d8ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
